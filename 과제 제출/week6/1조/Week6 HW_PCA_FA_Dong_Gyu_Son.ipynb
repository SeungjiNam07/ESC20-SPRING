{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 HW : PCA & FA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 3에서 했던 것을 그대로 가져와보자.\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "import pandas as pd\n",
    "pd.set_option('display.precision',3)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv('Wine.csv', header=None)\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      "Name                   178 non-null int64\n",
      "Alcohol                178 non-null float64\n",
      "MalicAcid              178 non-null float64\n",
      "Ash                    178 non-null float64\n",
      "AlcalinityOfAsh        178 non-null float64\n",
      "Magnesium              178 non-null int64\n",
      "TotalPhenols           178 non-null float64\n",
      "Flavanoids             178 non-null float64\n",
      "NonFlavanoidPhenols    178 non-null float64\n",
      "Proanthocyanins        178 non-null float64\n",
      "ColorIntensity         178 non-null float64\n",
      "Hue                    178 non-null float64\n",
      "OD280/OD315            178 non-null float64\n",
      "Proline                178 non-null int64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.5 KB\n"
     ]
    }
   ],
   "source": [
    "wine.columns = ['Name', \n",
    "                'Alcohol', \n",
    "                'MalicAcid', \n",
    "                'Ash', \n",
    "                'AlcalinityOfAsh', \n",
    "                'Magnesium', \n",
    "                'TotalPhenols', \n",
    "                'Flavanoids', \n",
    "                'NonFlavanoidPhenols', \n",
    "                'Proanthocyanins', \n",
    "                'ColorIntensity', \n",
    "                'Hue', \n",
    "                'OD280/OD315', \n",
    "                'Proline']\n",
    "# Week 3에서는 Feature Selection 시 변수를 선정해서 변수의 이름 지정하는 것이 중요\n",
    "# 그러나 PCA, FA에서는 변수들을 조합해버리기 때문에 별 의미가...없다...\n",
    "\n",
    "wine.info() # Cheking NA value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>MalicAcid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>AlcalinityOfAsh</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>TotalPhenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>NonFlavanoidPhenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>ColorIntensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>178.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.938</td>\n",
       "      <td>13.001</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.367</td>\n",
       "      <td>19.495</td>\n",
       "      <td>99.742</td>\n",
       "      <td>2.295</td>\n",
       "      <td>2.029</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1.591</td>\n",
       "      <td>5.058</td>\n",
       "      <td>0.957</td>\n",
       "      <td>2.612</td>\n",
       "      <td>746.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.775</td>\n",
       "      <td>0.812</td>\n",
       "      <td>1.117</td>\n",
       "      <td>0.274</td>\n",
       "      <td>3.340</td>\n",
       "      <td>14.282</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.572</td>\n",
       "      <td>2.318</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.710</td>\n",
       "      <td>314.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>11.030</td>\n",
       "      <td>0.740</td>\n",
       "      <td>1.360</td>\n",
       "      <td>10.600</td>\n",
       "      <td>70.000</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.410</td>\n",
       "      <td>1.280</td>\n",
       "      <td>0.480</td>\n",
       "      <td>1.270</td>\n",
       "      <td>278.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>12.362</td>\n",
       "      <td>1.603</td>\n",
       "      <td>2.210</td>\n",
       "      <td>17.200</td>\n",
       "      <td>88.000</td>\n",
       "      <td>1.742</td>\n",
       "      <td>1.205</td>\n",
       "      <td>0.270</td>\n",
       "      <td>1.250</td>\n",
       "      <td>3.220</td>\n",
       "      <td>0.782</td>\n",
       "      <td>1.938</td>\n",
       "      <td>500.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000</td>\n",
       "      <td>13.050</td>\n",
       "      <td>1.865</td>\n",
       "      <td>2.360</td>\n",
       "      <td>19.500</td>\n",
       "      <td>98.000</td>\n",
       "      <td>2.355</td>\n",
       "      <td>2.135</td>\n",
       "      <td>0.340</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4.690</td>\n",
       "      <td>0.965</td>\n",
       "      <td>2.780</td>\n",
       "      <td>673.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000</td>\n",
       "      <td>13.678</td>\n",
       "      <td>3.083</td>\n",
       "      <td>2.558</td>\n",
       "      <td>21.500</td>\n",
       "      <td>107.000</td>\n",
       "      <td>2.800</td>\n",
       "      <td>2.875</td>\n",
       "      <td>0.438</td>\n",
       "      <td>1.950</td>\n",
       "      <td>6.200</td>\n",
       "      <td>1.120</td>\n",
       "      <td>3.170</td>\n",
       "      <td>985.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000</td>\n",
       "      <td>14.830</td>\n",
       "      <td>5.800</td>\n",
       "      <td>3.230</td>\n",
       "      <td>30.000</td>\n",
       "      <td>162.000</td>\n",
       "      <td>3.880</td>\n",
       "      <td>5.080</td>\n",
       "      <td>0.660</td>\n",
       "      <td>3.580</td>\n",
       "      <td>13.000</td>\n",
       "      <td>1.710</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1680.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name  Alcohol  MalicAcid      Ash  AlcalinityOfAsh  Magnesium  \\\n",
       "count  178.000  178.000    178.000  178.000          178.000    178.000   \n",
       "mean     1.938   13.001      2.336    2.367           19.495     99.742   \n",
       "std      0.775    0.812      1.117    0.274            3.340     14.282   \n",
       "min      1.000   11.030      0.740    1.360           10.600     70.000   \n",
       "25%      1.000   12.362      1.603    2.210           17.200     88.000   \n",
       "50%      2.000   13.050      1.865    2.360           19.500     98.000   \n",
       "75%      3.000   13.678      3.083    2.558           21.500    107.000   \n",
       "max      3.000   14.830      5.800    3.230           30.000    162.000   \n",
       "\n",
       "       TotalPhenols  Flavanoids  NonFlavanoidPhenols  Proanthocyanins  \\\n",
       "count       178.000     178.000              178.000          178.000   \n",
       "mean          2.295       2.029                0.362            1.591   \n",
       "std           0.626       0.999                0.124            0.572   \n",
       "min           0.980       0.340                0.130            0.410   \n",
       "25%           1.742       1.205                0.270            1.250   \n",
       "50%           2.355       2.135                0.340            1.555   \n",
       "75%           2.800       2.875                0.438            1.950   \n",
       "max           3.880       5.080                0.660            3.580   \n",
       "\n",
       "       ColorIntensity      Hue  OD280/OD315   Proline  \n",
       "count         178.000  178.000      178.000   178.000  \n",
       "mean            5.058    0.957        2.612   746.893  \n",
       "std             2.318    0.229        0.710   314.907  \n",
       "min             1.280    0.480        1.270   278.000  \n",
       "25%             3.220    0.782        1.938   500.500  \n",
       "50%             4.690    0.965        2.780   673.500  \n",
       "75%             6.200    1.120        3.170   985.000  \n",
       "max            13.000    1.710        4.000  1680.000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = wine.iloc[:,1:] \n",
    "y = wine.iloc[:,0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 14, stratify = y)\n",
    "\n",
    "# PCA 시 Standard Scaling이 필수!\n",
    "X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "X_test_scaled = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.928023691631202,\n",
       " 2.4738364033982143,\n",
       " 1.4893951372526286,\n",
       " 0.985696111486994,\n",
       " 0.8517559482742454,\n",
       " 0.5858180912927305,\n",
       " 0.4365298556460181,\n",
       " 0.34368180802571124,\n",
       " 0.2923261011198424,\n",
       " 0.2569821861134573,\n",
       " 0.20024556720107642,\n",
       " 0.16975454422410577,\n",
       " 0.09164561124435035]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 큰 고유값들 순서로 뽑아내보자.\n",
    "\n",
    "X_train_scaled = pd.DataFrame(data=X_train_scaled, columns=wine.columns[1:])\n",
    "cov_mat = np.cov(X_train_scaled.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "eig_vals_ = sorted(eig_vals, reverse = True)\n",
    "eig_vals_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24fc35e90f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization of eigenvalues\n",
    "\n",
    "sns.lineplot(x = range(1, 14), y = eig_vals_, color = 'g', marker = 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.376, 0.565, 0.678, 0.754, 0.819, 0.863, 0.897, 0.923, 0.945,\n",
       "       0.965, 0.98 , 0.993, 1.   ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA() \n",
    "X_pca = pca.fit_transform(X_train_scaled) \n",
    "\n",
    "np.cumsum(pca.explained_variance_ratio_) \n",
    "\n",
    "# PC의 개수는 eigenvalue > 1 이거나 누적 explained variance > 최소 70~80% 인 지점을 선택해준다.\n",
    "# eigenvalue > 1 이면 component 3개이나 그러면 explained variance가 작다. 따라서 4개 선정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit Train - PCA : 1.0\n",
      "Logit Test - PCA : 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "# Pipeline을 통해서 한꺼번에 돌려보자.\n",
    "# Logistic Regression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "pca_pipe_1 = Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components = 4)),\n",
    "                    ('estimator', LR(solver='sag', max_iter=10000, multi_class='auto'))])\n",
    "pca_pipe_1.fit(X_train, y_train)\n",
    "\n",
    "print('Logit Train - PCA :', pca_pipe_1.score(X_train, y_train))\n",
    "print('Logit Test - PCA :', pca_pipe_1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Train - PCA : 0.9596774193548387\n",
      "LDA Test - PCA : 0.9074074074074074\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "pca_pipe_2 = Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components = 4)),\n",
    "                    ('estimator', LDA())])\n",
    "pca_pipe_2.fit(X_train, y_train)\n",
    "\n",
    "print('LDA Train - PCA :', pca_pipe_2.score(X_train, y_train))\n",
    "print('LDA Test - PCA :', pca_pipe_2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Train - PCA : 0.9838709677419355\n",
      "QDA Test - PCA : 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# QDA\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "pca_pipe_3 = Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components = 4)),\n",
    "                    ('estimator', QDA())])\n",
    "pca_pipe_3.fit(X_train, y_train)\n",
    "\n",
    "print('QDA Train - PCA :', pca_pipe_3.score(X_train, y_train))\n",
    "print('QDA Test - PCA :', pca_pipe_3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PC를 4개 선정했을 때 optimal한 방식은 Logistic Regression으로 보인다. \n",
    "Logistic Regression에서 굳이 polynomial features를 안해본 이유는...QDA test score가 제일 낮아서..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA하듯 FA도 해주면 된다.\n",
    "\n",
    "from sklearn.decomposition import FactorAnalysis as FA\n",
    "\n",
    "fa = FA()\n",
    "X_fa = fa.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.014</td>\n",
       "      <td>1.635</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.965</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>-1.859</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>0.218</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.395</td>\n",
       "      <td>-0.495</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.335</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.037</td>\n",
       "      <td>1.410</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.305</td>\n",
       "      <td>-0.592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6    7    8    9    10   11  \\\n",
       "0  1.014  1.635 -0.973 -0.188  0.675  0.282 -0.224  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.965 -0.411 -1.859 -0.935 -0.337  0.218 -0.139  0.0  0.0  0.0  0.0  0.0   \n",
       "2  1.395 -0.495  0.211  0.645  0.470  0.110  0.126  0.0  0.0  0.0  0.0  0.0   \n",
       "3  2.335  0.016  0.223  0.008  0.941  0.205  0.215  0.0  0.0  0.0  0.0  0.0   \n",
       "4 -0.037  1.410  0.093  0.744  0.434  0.305 -0.592  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    12  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fa = pd.DataFrame(data=X_fa)\n",
    "df_fa.head()\n",
    "\n",
    "# Factor는 7개로 선정해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LAB에 있는 것 그대로 돌려보기.\n",
    "\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "fa_1 = FactorAnalyzer(rotation='varimax')\n",
    "fa_1.fit(X)\n",
    "ev, v = fa_1.get_eigenvalues()\n",
    "xvals = range(1, X.shape[1]+1)\n",
    "\n",
    "plt.scatter(xvals, ev)\n",
    "plt.plot(xvals, ev)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Factor')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit Train - FA : 1.0\n",
      "Logit Test - FA : 0.9074074074074074\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "pca_pipe_4 = Pipeline([('fa', FA(n_components = 7)),\n",
    "                    ('estimator', LR(solver='sag', max_iter=10000, multi_class='auto'))])\n",
    "pca_pipe_4.fit(X_train, y_train)\n",
    "pca_pipe_4.score(X_test, y_test)\n",
    "\n",
    "print('Logit Train - FA :', pca_pipe_4.score(X_train, y_train))\n",
    "print('Logit Test - FA :', pca_pipe_4.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Train - FA : 0.9838709677419355\n",
      "LDA Test - FA : 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "\n",
    "pca_pipe_5 = Pipeline([('fa', FA(n_components = 7)), ('estimator', LDA())])\n",
    "pca_pipe_5.fit(X_train, y_train)\n",
    "\n",
    "print('LDA Train - FA :', pca_pipe_5.score(X_train, y_train))\n",
    "print('LDA Test - FA :', pca_pipe_5.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Train - FA : 1.0\n",
      "QDA Test - FA : 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "# QDA\n",
    "\n",
    "pca_pipe_6 = Pipeline([('fa', FA(n_components = 7)), ('estimator', QDA())])\n",
    "pca_pipe_6.fit(X_train, y_train)\n",
    "\n",
    "print('QDA Train - FA :', pca_pipe_6.score(X_train, y_train))\n",
    "print('QDA Test - FA :', pca_pipe_6.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor을 7개 선정했을 때 QDA가 제일 나은 방식으로 보인다. Quadratic일 때 score가 더 높으므로 여기서는 Logistic Regression w/ Polynomial Features까지도 고려를 해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit Poly2 Train - FA : 1.0\n",
      "Logit Poly2 Test - FA : 0.9259259259259259\n",
      "Logit Poly3 Train - FA : 1.0\n",
      "Logit Poly3 Test - FA : 0.9074074074074074\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression w/ Polynomial Features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pca_pipe_7 = Pipeline([('fa', FA(n_components = 7)), ('poly', PolynomialFeatures(degree = 2)),\n",
    "                    ('estimator', LR(solver='sag', max_iter=10000, multi_class='auto'))])\n",
    "pca_pipe_7.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "pca_pipe_8 = Pipeline([('fa', FA(n_components = 7)), ('poly', PolynomialFeatures(degree = 3)),\n",
    "                    ('estimator', LR(solver='sag', max_iter=10000, multi_class='auto'))])\n",
    "pca_pipe_8.fit(X_train, y_train)\n",
    "\n",
    "print('Logit Poly2 Train - FA :', pca_pipe_7.score(X_train, y_train))\n",
    "print('Logit Poly2 Test - FA :', pca_pipe_7.score(X_test, y_test))\n",
    "\n",
    "print('Logit Poly3 Train - FA :', pca_pipe_8.score(X_train, y_train))\n",
    "print('Logit Poly3 Test - FA :', pca_pipe_8.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하는 김에 3차까지 해보았으나 성능은 2차식에서 살짝 올라가나 3차에서는 그냥 그런 것으로 나타난다.\n",
    "\n",
    "따라서 PCA에서는 Logistic Regression이, FA에서는 QDA가 가장 적합한 것으로 결론낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparison with Past Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 3에서의 Feature Selection은 Univariate Selection w/ SelectKBest, Feature Importance w/ ExtraTreesClassifier 두 가지 방법으로 중복 선정된 상위 5개의 변수를 선정한 후 각각 Logistic Regression, LDA, QDA를 적용해보았다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression의 경우 아래의 결과로 나온다.\n",
    "\n",
    "Week 3\n",
    "Logit Train : 0.9435 / Logit Test : 0.9630\n",
    "\n",
    "PCA\n",
    "Logit Train : 1.0 / Logit Test : 0.9259\n",
    "\n",
    "FA\n",
    "Logit Train : 1.0 / Logit Test : 0.9074\n",
    "\n",
    "PCA나 FA의 경우 Train Set에서 완벽한 classification을 하지만 Test Set에서는 이보다 낮은 score을 갖는다. 하지만 Week 3에서는 Train Set에서는 다소 떨어지지만, Test에서 더 좋은 성능을 발휘한다고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA의 경우 아래의 결과로 나온다.\n",
    "\n",
    "Week 3\n",
    "LDA Train : 0.9113 / LDA Test : 0.9630\n",
    "\n",
    "PCA\n",
    "LDA Train : 0.9597 / LDA Test : 0.9074\n",
    "\n",
    "FA\n",
    "LDA Train : 0.9839 / LDA Test : 0.9259\n",
    "\n",
    "전반적으로 Logistic Regression의 경우와 비슷하게 나타난다. Train Set의 경우 PCA, FA에서 높게 나타나지만 Test Set의 경우 Week 3이 더 좋은 성능을 내고 있음을 보여주고 있다. 그러나 Logistic Regression의 경우와 비교해서 PCA가 FA보다 성능이 조금 떨어지는 것으로 나타났다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QDA의 경우 아래의 결과로 나온다.\n",
    "\n",
    "Week 3\n",
    "QDA Train : 0.9758 / QDA Test : 0.9815\n",
    "\n",
    "PCA\n",
    "QDA Train : 0.9839 / QDA Test : 0.8889\n",
    "\n",
    "FA\n",
    "QDA Train : 1.0 / QDA Test : 0.9815\n",
    "\n",
    "Week 3와 FA가 전체에서 가장 좋은 Test Score을 보이고 있으며 PCA는 전체에서 가장 낮은 Test Score을 보이고 있다. 그러나 PCA는 PC를 4개 선정한 것에 비해 Week 3는 변수 5개, FA는 Factor 7개를 선정하였으므로 과적합의 문제가 있을 수 있다고 생각한다. 이는 더 많은 자료가 확보되었을 때의 Test Score로 확인이 가능할 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
