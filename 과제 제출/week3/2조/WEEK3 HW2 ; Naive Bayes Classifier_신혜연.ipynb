{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WEEK3 HW2 ; Multinomial Naive Bayes Classifier; document classification_신혜연\n",
    "###신혜연\n",
    "##1.load the data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data = fetch_20newsgroups()\n",
    "data.target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: Data: <class 'list'> 2364 Target: <class 'numpy.ndarray'> 2364\n",
      "Test data: Data: <class 'list'> 1574 Target <class 'list'> 1574\n"
     ]
    }
   ],
   "source": [
    "##2.take four message categories and see what we get\n",
    "categories = ['comp.graphics', 'rec.autos', 'sci.electronics', 'sci.crypt']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "print(\"Training data:\", \"Data:\", str(type(train.data)), len(train.data), \"Target:\", str(type(train.target)), len(train.target))\n",
    "print(\"Test data:\", \"Data:\", str(type(test.data)), len(test.data), \"Target\", str(type(test.data)), len(test.target))\n",
    "\n",
    "### Among many features to distinct the word, we choose the \"frequency\" as the feature of the word. \n",
    "### f:= number of features\n",
    "###CountVectorizer : converts messages in form of text strings to feature vectors. ~> integrable\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.920584498094028\n"
     ]
    }
   ],
   "source": [
    "###3.make a classifier\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer  # an alternative feature extractor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "model.fit(train.data, train.target)\n",
    "labels_fitted = model.predict(test.data)\n",
    "print(\"Accuracy score is\", accuracy_score(labels_fitted, test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of feature matrix: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 20579)\t1\n",
      "  (0, 19220)\t1\n",
      "  (0, 29697)\t1\n",
      "  (0, 6320)\t1\n",
      "  (0, 25926)\t1\n",
      "  (0, 34222)\t1\n",
      "  (0, 31398)\t1\n",
      "  (0, 17883)\t1\n",
      "  (0, 16809)\t1\n",
      "  (0, 34425)\t1\n",
      "  (0, 23460)\t1\n",
      "  (0, 21787)\t1\n",
      "  (0, 11068)\t1\n",
      "  (0, 29494)\t1\n",
      "  (0, 29505)\t1\n",
      "  (0, 18436)\t1\n",
      "  (0, 24025)\t1\n",
      "  (0, 25336)\t1\n",
      "  (0, 12577)\t1\n",
      "  (0, 27517)\t1\n",
      "  (0, 30641)\t1\n",
      "  (0, 5980)\t1\n",
      "  (0, 29104)\t1\n",
      "  (0, 27521)\t1\n",
      "  (0, 11100)\t1\n",
      "  :\t:\n",
      "  (0, 17310)\t1\n",
      "  (0, 25400)\t1\n",
      "  (0, 23118)\t1\n",
      "  (0, 31686)\t6\n",
      "  (0, 27158)\t1\n",
      "  (0, 18085)\t1\n",
      "  (0, 12580)\t1\n",
      "  (0, 2100)\t1\n",
      "  (0, 20381)\t1\n",
      "  (0, 32729)\t1\n",
      "  (0, 23854)\t2\n",
      "  (0, 11079)\t1\n",
      "  (0, 15109)\t2\n",
      "  (0, 20509)\t1\n",
      "  (0, 23858)\t1\n",
      "  (0, 26624)\t1\n",
      "  (0, 30377)\t1\n",
      "  (0, 16034)\t1\n",
      "  (0, 19099)\t1\n",
      "  (0, 13317)\t6\n",
      "  (0, 34790)\t6\n",
      "  (0, 9553)\t4\n",
      "  (0, 21852)\t5\n",
      "  (0, 18962)\t3\n",
      "  (0, 15373)\t1\n"
     ]
    }
   ],
   "source": [
    "###4.look at the resulting feature vectors.\n",
    "vec=CountVectorizer()\n",
    "features=vec.fit_transform(train.data)\n",
    "print(\"Type of feature matrix:\", type(features))\n",
    "print(features[0,:])        # print the features of the first sample point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 177\n",
      "Word 'it' appears in the first message 2 times.\n",
      "\n",
      "From: jgfoot@minerva.cis.yale.edu (Josh A. Goldfoot)\n",
      "Subject: Re: Organized Lobbying for Cryptography\n",
      "Organization: Yale University\n",
      "Lines: 21\n",
      "Distribution: inet\n",
      "Reply-To: jgfoot@minerva.cis.yale.edu\n",
      "NNTP-Posting-Host: minerva.cis.yale.edu\n",
      "X-Newsreader: TIN [version 1.1 Minerva PL9]\n",
      "\n",
      "Shaun P. Hughes (sphughes@sfsuvax1.sfsu.edu) wrote:\n",
      ": In article <1r3jgbINN35i@eli.CS.YALE.EDU> jgfoot@minerva.cis.yale.edu writes:\n",
      "[deletion]\n",
      ": >Perhaps these encryption-only types would defend the digitized porn if it\n",
      ": >was posted encrypted?\n",
      ": >\n",
      ": >These issues are not as seperable as you maintain.\n",
      ": >\n",
      "\n",
      ": Now why would anyone \"post\" anything encrypted? Encryption is only of \n",
      ": use between persons who know how to decrypt the data.\n",
      "\n",
      ": And why should I care what other people look at? \n",
      "\n",
      "I was responding to another person (Tarl Neustaedter) who held that the\n",
      "EFF wasn't the best organization to fight for crytography rights since the\n",
      "EFF also supports the right to distribute pornography over the internet,\n",
      "something some Crypto people might object to. In other words, he's\n",
      "implying that there are people who will protect any speech, just  as long\n",
      "as it is encrypted.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### first message에 얼마나 많은 단어가 있냐?\n",
    "print(\"Number of words:\", features[0,:].sum())\n",
    "col = vec.vocabulary_[\"it\"]   # Get the column of 'it' word in the feature matrix\n",
    "print(f\"Word 'it' appears in the first message {features[0, col]} times.\")\n",
    "print()\n",
    "print(train.data[0])   # Let's print the corresponding message as well\n",
    "#print(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####원래 파일 다운 받은 후 spam dection function을 만드려고 했었는데 시간이 없어 미완인 채로 제출합니다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
