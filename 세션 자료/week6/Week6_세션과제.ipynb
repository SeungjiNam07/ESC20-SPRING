{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Session :: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eigen decomposition 을 이용한 PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate toy dataset\n",
    "np.random.seed(4)\n",
    "m = 60\n",
    "w1, w2 = 0.1, 0.3\n",
    "noise = 0.1\n",
    "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "X = np.empty((m, 3))\n",
    "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
    "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "X[:, 2] = X[:, 0] * w1 + X[:, 1] * w2 + noise * np.random.randn(m)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA를 수행하기 위해 먼저 공분산행렬을 구합니다.\n",
    "X_cen = X - X.mean(axis=0)  # scaling\n",
    "X_cov = np.dot(X_cen.T, X_cen) / 59 # covariance matrix\n",
    "\n",
    "print(X_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음으로 공분산행렬 X_cov에 대하여 eigenvalue와 eigenvector를 구합니다.\n",
    "w, v = np.linalg.eig(X_cov)\n",
    "\n",
    "print('eigenvalue :', w)\n",
    "print('eigenvector :', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막으로 데이터에 대한 eigenvector들의 설명력을 확인합니다.\n",
    "print('explained variance ratio :', w / w.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition을 이용한 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate toy dataset\n",
    "np.random.seed(4)\n",
    "m = 60\n",
    "w1, w2 = 0.1, 0.3\n",
    "noise = 0.1\n",
    "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "X = np.empty((m, 3))\n",
    "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
    "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "X[:, 2] = X[:, 0] * w1 + X[:, 1] * w2 + noise * np.random.randn(m)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA를 수행하기 위해 먼저 데이터셋 X를 스케일링 합니다.\n",
    "X_cen = X - X.mean(axis=0)  # scaling\n",
    "\n",
    "print(X[0:5])\n",
    "print(X_cen[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음으로 X_cen에 대하여 singular value와 singular vector를 구합니다.\n",
    "U, D, V_t = np.linalg.svd(X_cen)\n",
    "\n",
    "print('singular value :', D)\n",
    "print('singular vector :\\n', V_t.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막으로 설명력을 확인합니다.\n",
    "print('explained variance ratio :', D ** 2 / np.sum(D**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 LAB :: PCA & FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names']+['target'])\n",
    "df['target'] = df['target'].map({0:'setosa', 1:'versicolor', 2:'virginica'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 scaling을 실시합니다.\n",
    "# Transform scales onto unit scale (mean=0 and variance=1)\n",
    "features = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "X = df.loc[:, features].values\n",
    "y = df.loc[:, ['target']].values\n",
    "\n",
    "X = StandardScaler().fit_transform(X) # Standardization using Standard Scaler\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=X, columns=features).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음으로 공분산행렬을 구합니다.\n",
    "covariance_matrix = np.cov(X.T)\n",
    "\n",
    "print(covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공분산행렬에 대하여 eigenvalue와 eigenvector를 구합니다.\n",
    "eig_vals, eig_vecs = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "print('eigenvalue :', eig_vals) # eigen values\n",
    "print('eigenvector :', eig_vecs) # eigen vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 큰 고유값인 2.93808505을 갖는 eigen vector가 제1주성분이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA를 진행합니다.\n",
    "pca = PCA(n_components=2) # PCA 선언 : 2차원으로 차원 축소 => 제1주성분, 제2주성분 총 2개의 주성분 반환\n",
    "X_pca = pca.fit_transform(X) # PCA 적합\n",
    "\n",
    "df_pca = pd.DataFrame(data=X_pca, columns=['Principal Component 1', 'Principal Component 2'])\n",
    "df_pca = pd.concat([df_pca, df[['target']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 결과를 시각화를 통해 확인합니다.\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(x = df_pca['Principal Component 1'], y = df_pca['Principal Component 2'], hue = finalDf['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주성분들의 설명력을 확인합니다.\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PC1은 데이터를 약 72% 정도, PC2는 23% 정도 설명합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor Analysis : scikit-learn의 FactorAnalysis 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create factor analysis object and perform factor analysis\n",
    "X = df.loc[:, features].values\n",
    "fa = FactorAnalysis(n_components=10)\n",
    "X_fa = fa.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fa = pd.DataFrame(data=X_fa, columns=['Factor1', 'Factor2', 'Factor3', 'Factor4'])\n",
    "df_fa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor1과 Factor2만 유의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(x = df_fa['Factor1'], y = df_fa['Factor2'], hue=df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor Analysis : factor_analyzer의 FactorAnalyzer 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "fpath = './bfi.csv'\n",
    "df = pd.read_csv(fpath, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df.drop(['gender', 'education', 'age'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a factor analyzer variable and perform factor analysis\n",
    "fa = FactorAnalyzer(n_factors=6, rotation='varimax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the eigenvectors and eigenvalues\n",
    "ev, v = fa.get_eigenvalues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a scree plot\n",
    "xvals = range(1, df.shape[1]+1)\n",
    "\n",
    "plt.scatter(xvals, ev)\n",
    "plt.plot(xvals, ev)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Factor')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week6 HW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wine dataset을 활용하여 PCA 혹은 FA를 적용한 후, 적용하기 전과 적용한 후 분류모델의 성능을 비교해주세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
